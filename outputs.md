Example link https://medium.com/the-research-nest/explained-transformers-for-everyone-af01cbe600c5

Experiment using: Simple parser with Latent Semantic Analysis (LSA)
Output:
```
'Once that’s done, you have your “AI model” to generate new responses based on everything learned from the training data. In technical terms, attention mechanisms calculate weights, determining how much focus is put on each part of the input data. This process helps the model build a deep understanding of how words are related to each other and what actually makes sense. If you want to learn more about “tokens” and “embeddings (the special numbers as I refer them),” check out my other article below. I intentionally did not touch upon the exact mathematical concepts or equations used in each layer to avoid unnecessary complications.'
```
Experiment using: Bart-CNN - Clealy for this Scrapping needs to be improved
```
Learn how to build an AI model in simple (yet complex) steps. Take a look at the underlying architecture of modern LLMs XQ Follow The Research Nest. Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com and CNN iReport.
```
